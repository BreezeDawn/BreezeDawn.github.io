<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用Hexo+Github搭建个人博客(详细)]]></title>
    <url>%2F2018%2F10%2F30%2F%E4%BD%BF%E7%94%A8Hexo-Github%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2-%E8%AF%A6%E7%BB%86%2F</url>
    <content type="text"><![CDATA[搭建环境准备： 下载Node.js 安装Git 拥有github账号 下载完成后（全部按NEXT就好），按下WIN+R，调出运行窗口，打cmd回车进入命令行，验证node和Git是否安装正确，输入下面指令: 123node -vnpm -vgit --version 如果都安装成功就会显示对应的软件版本号。 安装Hexo进去你要放置博客文件夹的目录，点击鼠标右键，点击 Git Bash Here，然后依次输入并执行下面的代码。 12345$ npm install hexo-cli -g $ hexo init Hexo$ cd Hexo$ npm install$ hexo server 第一行是安装 hexo 扩展插件。 第二行是创建一个为 Hexo 的文件夹，我们要把 hexo 相应的代码下载到该文件中下。 第三行进入到新创建的文件夹内。 第四行是安装 hexo 相关的代码。 第五行启动本地服务，启动完成后，在浏览器输入 http://localhost:4000/ 就可以访问刚刚创建的博客了。 如果报错: 执行 npm cache clean --force 清缓存再安装 Hexo目录里会多出很多文件，此时的目录情况如下: 123456node_modules npm 文件缓存目录scaffolds 文夹件下存放文章和页面模版scource 文夹件下存放资源文件themes 文夹件下存放主题文件package.json 站点版本和站点所需的依赖文件_config.yml 站点配置文件 hexo 常用命令 ： 12345678$ hexo g 生成静态文件$ hexo s 启动本地服务$ hexo d 提交到远程仓库$ hexo n page 创建页面 $ hexo n &quot;&quot; 创建文章$ hexo d -g 生成静态并提交到远程仓库$ hexo s -g 生成静态文件并启动本地预览$ hexo clean 清除本地 public 文件 外网访问第一步 - 创建仓库在 Github 创建一个名字为 username.github.io 的仓库，这里的 username 必须是你的github用户名。 第二步 - 修改配置注意所有的命令都在git-bash里敲! 注意所有的命令都在git-bash里敲! 注意所有的命令都在git-bash里敲! 注意所有的配置冒号后都要有空格! 注意所有的配置冒号后都要有空格! 注意所有的配置冒号后都要有空格! 修改depoly ，这里的 username 仍然是你的 Github 用户名： 1234deploy: type: git repo: git@github.com:username/username.github.io.git // 后面对应的是仓库链接 branch: master 示例： 1234deploy: type: git repo: git@github.com:BreezeDawn/BreezeDawn.github.io.git branch: master 修改 site 相关信息 ： 1234567title: xxsubtitle: description: 中文最好用编辑器不要用记事本打开keywords:author: xxlanguage: zh-Hanstimezone: 注 ：网站名称（title），作者 (author)，语言 (language)，签名(description) 第三步 - 给本地 Git 添加 ssh免密登陆首先我们需要修改 Git 的全局配置 user.name 和user.email 12git config –-global user.name “xxxxxx” // 自己的 github 用户名git config –-global user.email “xxxxxx” // 自己的 github 里绑定的邮箱 在这里 user 不需要替换成自己…..只需要修改双引号里的内容 然后我们进入存放密匙的文件夹，检查本地是否有 SSH key 12$ cd ~/.ssh$ ls 如果 SSH key 存在，就会显示 id_rsa、id_rsa.pub、know_hosts 三个文件 。 没有的话我们就来创建 SSH key 1$ ssh-keygen -t rsa -C &quot;你的邮箱&quot; 然后点击回车，接着会让你输入文件名，点击回车直接忽略，再然后会让设置密码并确认密码，我们点击两次回车，直接把密码设置为空，不用输入 。然后你会看到一堆泡泡，说明密匙创建成功。 创建成功后，可以通过如下命令拷贝 SSH key 的内容 ： 1clip &lt; ~/.ssh/id_rsa.pub&quot; 你也可以手动打开~/.ssh/目录下的id_rsa.pub文件进行拷贝，所有内容一字不漏的拷贝! 然后我们打开 GitHub 点击右上角头像进入个人资料，点击Settings -&gt; 左边 SSH and GPG keys，然后点击 New SSH key，title随便填，把之前拷贝的内容粘贴到 key 里面，然后点击 Add SSH key。 怎么去验证是否已经添加成功了呢 ？通过如下命令 ： 1$ ssh -T git@github.com 验证成功，你会看到 successfully !! 但是我们还差一步~ 第四步 - 更新静态文件，提交到 github 仓库执行 $ npm install hexo-deployer-git --save - 安装关联 Github 的插件 执行 hexo d -g - 更新静态文件并提交到你的 github 仓库。 然后使用浏览器打开 https://username.github.io.git ，是不是可以外网访问了呢? 记住一定是https的哦，不然访问不到 更换主题下载主题如果不喜欢现在的主题，我们可以在 github 中搜索 hexo theme 寻找自己喜欢的主题。 我用的是人气最高的 Next 主题，它提供非常详尽的官方文档，并且支持很多第三方插件，十分的友好。 Next Github：https://github.com/iissnan/hexo-theme-next/ Next 官方文档：http://theme-next.iissnan.com/ 我们现在通过 git 方式下载 Next，命令如下 ： 12$ cd themes$ git clone https://github.com/iissnan/hexo-theme-next next hexo 的主题文件都放在 themes 文件夹下，所以我们要进入主题文件夹 下下载 Next。 下载完成后，我的博客 themes 下就多了一个 next 文件夹。 配置主题首先我们要区分两个文件。 第一个是我们网站的 站点配置文件 _config.yml，它在我们的博客根目录 Hexo/下，Hexo 为 hexo init 初始化时自动创建的文件夹名称。 第二个是我们网站的 主题配置文件 _config.yml，它在我们的主题目录 Hexo/themes/next下。 然后我们修改 站点配置文件 : 1theme : next 注 ：把默认主题 landscape 切换成 next。 此时我们的博客主题已经修改为 Next 主题，但 Next 主题其实有四个风格，Muse、Mist、Pisces、Gemini，且这里默认为 Muse。 如果我们想要修改，就需要打开 主题配置文件， 修改 Schemes ： 1234scheme: Muse#scheme: Mist#scheme: Pisces#scheme: Gemini 根据自己的选择进行注释。 修改完毕后我们需要把静态文件按照新的配置重新生成，还记得重新生成静态文件的命令吗? 1$ hexo g 然后我们就可以提交给远程仓库了 1$ hexo d 完结接下来我们就可以在 github 上看见我们提交的静态文件了，也可以通过 https://username.github.io/ 访问我们的博客了，username 改成你的github 用户名，一定要记得是https!! 如果你想发布文章、生成新页面、增加搜索或其他功能，在 Next 官方文档中你都能找到~ 再放一下官方文档： Next 官方文档：http://theme-next.iissnan.com/ 当然还有一些不在官方文档上的骚操作，等我更新吧… 如果在进行操作时有 bug ，欢迎留言~~]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习-神经网络(一)]]></title>
    <url>%2F2018%2F10%2F29%2FMachineLearning-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[为什么要使用神经网络当特征太多时，计算的负荷会特别大，而普通的线性回归/逻辑回归都无法有效地处理这么多的特征，这个时候我们需要神经网络。 神经网络的模型表示首先，我们为神经网络里的每一层都增加了一个偏差单元，即每一层的0号下标的单元，它的值永远为1，而偏差单元我们只在当作输入时使用。 这时，我们把输入的样本特征$x_0x_1x_2x_3$看作第一层输入，$a_1a_2a_3$看作第一层的输出，把$a_0a_1a_2a_3$看作第二层的输入，$h_\theta(x)$看作第二层的输出。 PS：输出的意思就是经过一个激励函数$g(z)$的运算得出的，这里：$$g(z)=\frac{1}{1+e^{-z}}$$ 输出怎么得到从线性回归中我们能够知道：$h_\theta(x) = \theta_0x_0+\theta_1x_1+\theta_2x_2+\theta_3x_3 = y$ 如果我们想要使用相同的输入 $x_0x_1x_2x_3$ 得出一个不一样的 $y_1$ ，我们必须要改变 $\theta$的值使得与第一次运算的 $\theta$ 不一样。 同理，当我们把输入的样本特征 $x_0x_1x_2x_3$ 看作第一层输入时，我们就需要三组不同的 $\theta$ 值，使得经过激励函数后得到三个不同的值 $a_1a_2a_3$。因此，我们就有了关于第一层输入的 $\theta$ 矩阵 $\Theta^{(1)}$，它的尺寸为 3*4。那么第二层输入的 $\theta$ 矩阵 $\theta^{(2)}$ 的尺寸则为 1*4。当然我们也可能会有许多次输入输出，如果我们进行多次的输入输出，$a_{i}^{\left( j \right)}$ 则代表第 $j$ 层的第 $i$ 个激活单元(输入)。${\theta }^{\left( j \right)}$代表从第 $j$ 层映射到第 $ j+1$ 层时的权重的矩阵，例如 ${\theta }^{\left( 1 \right)}$ 代表从第一层映射(输出)到第二层的权重的矩阵。其尺寸为：以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。 输入-输出的过程因为 $a_1a_2a_3$ 是样本特征 $x_0x_1x_2x_3$ 与 $\Theta^{(1)}$ 经过激励函数后得到的值，因此此过程可写为： $a_{1}^{2}=g(\Theta_{10}^{1}x_{0}+\Theta_{11}^{1}x_{1}+\Theta_{12}^{1}x_{2}+\Theta_{13}^{1}x_{3})$ $a_{2}^{2}=g(\Theta_{20}^{1}x_{0}+\Theta_{21}^{1}x_{1}+\Theta_{22}^{1}x_{2}+\Theta_{23}^{1}x_{3})$ $a_{3}^{2}=g(\Theta_{30}^{1}x_{0}+\Theta_{31}^{1}x_{1}+\Theta_{32}^{1}x_{2}+\Theta_{33}^{1}x_{3})$ $h_\Theta(x)=g(\Theta_{10}^{2}a_{0}^{2}+\Theta_{11}^{2}a_{1}^{2}+\Theta_{12}^{2}a_{2}^{2}+\Theta_{13}^{2}a_{3}^{2})$ 上面进行的讨论中只是将特征矩阵中的一行（一个训练实例）喂给了神经网络，我们需要将整个训练集都喂给我们的神经网络算法来学习模型。 我们可以知道：每一个 $a$ 都是由上一层所有的$x$和每一个$x$所对应的决定的。 （我们把这样从左到右的算法称为前向传播算法( FORWARD PROPAGATION )） 把$x$, $\theta$, $a$ 分别用矩阵表示： 我们可以得到 $g(\theta \cdot X)=a$ 。 如果细分下去，我们就能够得到向量化的结果：$$g(\Theta^{(1)}\cdot{X^T})=a^{(2)}$$ 即： 以上是以第一层为例进行的说明，那么现在我们看第二层，则有$$g(\Theta^{(2)}\cdot a^{(2)})=h_\theta(x)$$我们令 ${z}^\left( 3 \right)={\theta }^{( 2 )}{a}^{( 2 )}$，则 $h_\theta(x)={a}^{\left(3\right)}=g({z}^{\left(3\right)})$。 更好的理解 其实神经网络就像是logistic regression，只不过我们把logistic regression中的输入向量$[ x_1\sim {x_3} ]$ 变成了中间层的$[ a_1^{(2)}\sim a_3^{(2)} ]$, 即: $h_\theta(x)=g( \Theta_0^{ 2 }a_0^{ 2 }+\Theta_1^{ 2 }a_1^{ 2 }+\Theta_{2}^{ 2 }a_{2}^{ 2 }+\Theta_{3}^{ 2 }a_{3}^{ 2 } )$ 我们可以把 $a_0, a_1, a_2, a_3$ 看成更为高级的特征值，也就是 $x_0, x_1, x_2, x_3$ 的进化体，并且它们是由 $x$与$\theta$决定的，因为是梯度下降的，所以 $a$ 是变化的，并且变得越来越厉害，所以这些更高级的特征值远比仅仅将 $x$次方厉害，也能更好的预测新数据。这就是神经网络相比于逻辑回归和线性回归的优势。从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制为使用数据中的原始特征 $x_1,x_2,…,{x}_{n}$ ，我们虽然可以使用一些二项式项来组合这些特征，但是我们仍然受到这些原始特征的限制。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输出变量的新特征。 单层神经元计算的简化理解神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(AND)、逻辑或(OR)。当输入特征为布尔值（0或1）时，我们可以用一个单一的激活层可以作为二元逻辑运算符，为了表示不同的运算符，我们只需要选择不同的权重即可。 在理解之前，我们再复习一下关于激励函数与判定边界。当$g(z)$中 $z &gt; 0$ 时，$g(z)$ &gt; 0.5 ，假如我们的阈值就是 0.5，那么我们此时就把 $g(z)$ 的结果归为 1 ，反之则为 0。 逻辑与那么，如果我们现在有输出函数 $h_\theta(x) = g(\theta_0x_0+\theta_1x_1+\theta_2x_2)$，且 $\Theta = [-30,20,20]$，此时 $h_\theta(x) = g(-30+20x_1+20x_2)$，我们就能够得到$x_1x_2$分别取值时的结果对照表： 经过复习和上表的对照我们能够很轻松的理解。 此时$h_\theta(x)$ 得出的结果 等于 $x_1 AND x_2$ 得出的结果，因此我们就能够把此时的输出函数中进行的计算简化理解为：对输入做 逻辑与(AND)​ 运算。 逻辑或而当 $\Theta = [-10,20,20]$ 时，此时 $h_\theta(x) = g(-10+20x_1+20x_2)$ ，我们就能够得到$x_1x_2$分别取值时的结果对照表： 此时$h_\theta(x)$ 得出的结果 等于 $x_1 OR x_2$ 得出的结果，因此我们就能够把此时的输出函数中进行的计算简化理解为：对输入做 逻辑或(OR) 运算。 逻辑非当 $\Theta = [10,-20,0]$ 时，此时 $h_\theta(x) = g(10-20x_1)$ ，我们就能够知道$x_1$取 0 时，结果为 1，$x_1$取 1 时，结果为 0 。我们就能够把此时的神经元的作用等同于 逻辑非(NOT) XNOR(输入两个值相等时，结果为 1 )那么我们如何表示呢? 首先我们构造一个能表达 $(NOT x_1) AND (NOTx_2)$ 的神经元进行第一层计算，如图： 然后构造一个能表示 OR 的神经元进行第二层计算，再让这两层组合在一起： 这样我们就得到了一个能实现 $\text{XNOR}$ 功能的神经网络。 因此，我们能够组合三种简单的运算来逐渐构造出复杂的函数，这样我们也能得到更加复杂有趣的特征值。 这就是神经网络的厉害之处。 多类处理的神经网络我们在上面的神经网络仅仅输出了一个结果，也就是我们只做了二分类问题，那么我们如果想要进行多个类的分类呢? 很简单，我们只需要让结果值的数目等于你要分类的类数目。比如说：如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。第一个值为1或0用于预测是否是行人，第二个值用于判断是否为汽车，第三个值用于预测是否是摩托车，第四个值用于判断是否为卡车。 如果我们构造两个中间层进行，输出层4个神经元分别用来表示4类，那么神经网络图可能如下所示： 我们希望当输入人的图片时，输出的结果为 [1 , 0, 0, 0]，输入卡车图片时，输出的结果为 [0 , 0, 0, 1]。 这样，我们就实现了神经网络的多分类处理。 如果对你有所帮助，点个赞吧 ！ 查看我的CSDN: https://blog.csdn.net/qq_28827635]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经验]]></title>
    <url>%2F2018%2F10%2F28%2F%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[讲述人简介 工作半年 学历 - 硕士 做的人工智能的自然语言处理，招聘系统里的算法组， 只面试了一家，当时找的数据挖掘，看重了学习能力留下来进了算法组，当场给的offer 填简历几个维度去看你,让你的简历更容易被别人记下来 薪资填一下无论HR还是自己都对自己有预期，可以填一下 职能与投递的公司契合度在哪里 学历 很看重，四六级，211与否，本科or硕士，占不到优势就只能侧重于技能方向 技能(重点) 无论做什么方向，讲述自己具备技能时需要有自己的特色，或者说相比于别人你需要更好的去表述自己擅长的方面：宏观上你对项目的贡献，微观上贡献的技术点深入(吹)，学会吹 ：），吹牛逼不是撒谎 = =/。注意细节，描述的越细越真，不能含糊 自学能力描述自己的学习过程，遇到的困难坎坷，表现出自己的自学能力很强 热情要嗨起来，展示对技术的追求与对未知的好奇心，正能量 关于不是本专业的(非科班)，怕受到歧视不用担心，大部分科班都是走的校招找工作，而我们去找工作是社招，别人看重的是我们的技能，讲述人所在的算法组中都不是计算机本专业的，在公司，周围的同事大部分也不是本专业的，所以不用太担心，嗨起来 关于爬虫可能你们分布式爬虫都搞不出来，老师教的很有限，目前来讲爬虫方向的门槛很高，讲述人的公司面了很多爬虫最后都没有要 关于就业讲述人建议，当前的问题就在于就业，想走高端方向可以慢慢学，但是目前来讲没有经济基础还是先就业比较好，要现实一点先找到工作，目前的测试需求非常大，他的朋友就是先工作然后转到了算法工程师，python就是一个起点，也就是从零到一的开始，先开个头，再莽。 建议 住的地方离公司近一点，开销会少很多 把目前的公司当跳板，好好利用周末时间进行个人技能的提升 简历有老师辅导很简单了，重点就在面试了，注意细节，要嗨起来 数据结构与算法最好系统的学一学，有手写算法的面试题的都用的上]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习-正则化]]></title>
    <url>%2F2018%2F10%2F27%2FMachineLearning-%E6%AD%A3%E5%88%99%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1. 正则化它可以改善或者减少过度拟合问题 2. 欠拟合(模型的高偏差)欠拟合是指模型拟合程度不高，数据距离拟合曲线较远，或者模型没有很好地捕捉到数据特征，不能够很好地拟合数据。 3. 过拟合(模型的高方差)为什么出现过拟合 特征过多 训练集数据较少 模型复杂 对过拟合的理解如果我们拟合一个高阶多项式，那么这个函数能很好的拟合训练集能拟合几乎所有的训练数据，这就面临可能函数太过庞大的问题，即变量太多。同时如果我们没有足够的数据去约束这个变量过多的模型，就会出现过度拟合的情况。虽然训练出的模型能够很好的拟合训练集的样本数据，但很有可能无法泛化新样本。 如何解决过拟合 尽量减少选取特征数量。后面会学到模型选择算法 ，它能够自动选择采用哪些特征变量，且自动舍弃不需要的变量 正则化保留所有特征变量，但是减少参数$\theta_j$的大小 4. 怎么应用正则化思想与做法修改代价函数，从而收缩(惩罚)所有的参数值，因为我们并不知道具体的去收缩(惩罚)哪些参数， 修改后的代价函数如下：$$J\left(\theta\right)=\frac{1}{2m}[\sum\limits_{i=1}^{m}{({h_\theta}({x}^{(i)})-{y}^{(i)})^{2}+\lambda \sum\limits_{j=1}^{n}\theta_{j}^{2}]}$$$\lambda $又称为正则化参数（Regularization Parameter），它能够平衡代价函数，使$\theta_j$尽可能的小。 注：根据惯例，我们的$j$是从1开始的，也就是我们不对${\theta_{0}}$ 进行惩罚。 举一个例子我们看这个假设函数: $h_\theta\left( x \right)=\theta_{0}+\theta_{1}x_{1}+\theta_{2}x_{2}^2+\theta_{3}x_{3}^3+\theta_{4}x_{4}^4$ 。通常地，正是那些高次项导致了过拟合的产生，所以如果我们能让这些高次项的系数接近于0的话，我们就能很好的拟合了。于是我们将修改代价函数，在其中${\theta_{3}}$和${\theta_{4}}$ 设置一点惩罚。这样做的话，我们在尝试最小化代价时也需要将这个惩罚纳入考虑中，并最终导致选择较小一些的${\theta_{3}}$和${\theta_{4}}$。修改后如下 :$$\underset{\theta}{\mathop\min }\,\frac{1}{2m}[\sum\limits_{i=1}^{m}{\left({h}_{\theta }\left( {x}^{(i)} \right)-{y}^{(i)} \right)^{2}+1000\theta _{3}^{2}+10000\theta _{4}^{2}]}$$但是正是因为我们并不知道具体的哪一个$\theta$是高次项，因此我们只能去收缩(惩罚)所有参数。 但是如果我们令 $\lambda$ 的值很大的话，那么$\theta $（不包括${\theta_{0}}$）都会趋近于0，这样我们所得到的只能是一条平行于$x$轴的直线。所以对于正则化，我们要取一个合理的 $\lambda$ 的值，这样才能更好的应用正则化。 5. 正则化线性回归正则化代价函数$$J\left(\theta\right)=\frac{1}{2m}\sum\limits_{i=1}^{m}{[(({h_\theta}({x}^{(i)})-{y}^{(i)})}^{2}+\lambda \sum\limits_{j=1}^{n}{\theta _{j}^{2})]}$$ 正则化梯度下降要使梯度下降法令正则化后的线性回归代价函数最小化，因为我们没有对$\theta_0$进行正则化，所以梯度下降算法有两种情形：$${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}(({h_\theta}({x}^{(i)})-{y}^{(i)})x_{0}^{(i)})$$ $${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}({h_\theta}({x}^{(i)})-{y}^{(i)})x_{j}^{\left(i\right)}+\frac{\lambda }{m}{\theta_j}]$$ 对第二个式子进行变化后，可得:$${\theta_j}:={\theta_j}(1-a\frac{\lambda }{m})-a\frac{1}{m}\sum\limits_{i=1}^{m}({h_\theta}({x}^{(i)})-{y}^{(i)})x_{j}^{\left(i\right)}$$可以看出，正则化线性回归的梯度下降算法的变化在于，每次都在原有算法更新规则的基础上令$\theta $值减少了一个额外的值。 PS：梯度下降仍然是对$J(\theta)$进行最小化，通过求导，得出梯度下降算法 正则化正规方程 注：图中的矩阵尺寸为 $(n+1)*(n+1)$。 值得一提的是，哪怕此时$X$不可逆，经过$\lambda$相加变化后的矩阵将是可逆的。 6. 正则化逻辑回归正则化代价函数$$J\left(\theta\right)=\frac{1}{m}\sum\limits_{i=1}^{m}{[-{y}^{(i)}\log \left({h_\theta}\left({x}^{(i)}\right)\right)-\left(1-{y}^{(i)} \right)\log\left(1-{h_\theta}\left({x}^{(i)}\right) \right)]}+\frac{\lambda}{2m}\sum\limits_{j=1}^{n}\theta _{j}^{2}$$ ​ ps：注意这里$\lambda$的仍为$\frac{1}{2m}$ 正则化梯度下降类似地，因为我们没有对$\theta_0$进行正则化，所以梯度下降算法有两种情形：$${\theta_0}:={\theta_0}-a\frac{1}{m}\sum\limits_{i=1}^{m}(({h_\theta}({x}^{(i)})-{y}^{(i)})x_{0}^{(i)})$$ $${\theta_j}:={\theta_j}-a[\frac{1}{m}\sum\limits_{i=1}^{m}({h_\theta}({x}^{(i)})-{y}^{(i)})x_{j}^{\left( i \right)}+\frac{\lambda }{m}{\theta_j}]$$ 看起来和线性回归的一模一样，实际上我们知道这里 ${h_\theta}\left( x \right)=g\left( {\theta^T}X \right)$，所以与线性回归不同。 PS：值得注意的是，${\theta_{0}}$仍然不参与其中的任何一个正则化。 注:泛化能力（generalization ability）泛化能力是指机器学习算法对新鲜样本的适应能力。学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的模型也能给出合适的输出，该能力称为泛化能力。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-逻辑回归]]></title>
    <url>%2F2018%2F10%2F25%2FMechineLearning-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%2F</url>
    <content type="text"><![CDATA[什么是逻辑回归逻辑回归算法是分类算法，可能它的名字里出现了“回归”让我们以为它属于回归问题，但逻辑回归算法实际上是一种分类算法，它主要处理当 $y$ 取值离散的情况，如：1 0 。 为什么不使用线性回归算法处理分类问题假设我们遇到的问题为 二分类问题，那么我们可能将结果分为负向类和正向类，即$y\in0,1$ ，其中 0 表示负向类，1 表示正向类。如果我们使用线性回归，那么假设函数的输出值可能远大于 1，或者远小于0，但是我们需要的假设函数输出值需要在0到 1 之间，因此我们需要用到逻辑回归算法。 逻辑回归的假设函数与理解逻辑回归的假设函数 sigmoid function 表示方法 :$$h_\theta(x) = \frac{1}{1+e^{-\theta^Tx}}$$ 理解记忆:其实里面的$\theta_Tx$就是线性回归时的假设函数 h(x) ，$$h(x) = \theta^Tx = \sum_{j=0}^{n}{\theta_jx_j}$$而逻辑回归的假设函数其实就是将线性回归的表达式 h(x) 以 z 的形式代入到了 S 型函数(sigmoid function) 中 :$$g(h(x)) = g(z) = \frac{1}{1+e^{-z}}$$ps: 这里我们用$h(x)$表示的是线性回归的假设函数，之后的$h$都将表示 逻辑回归的假设函数。值得一提的是S型函数和我们的假设函数没关系，它只是一个输出值在0~1之间的函数，仅此而已。我们做的只是把之前得到的线性回归假设函数给代入进去形成逻辑回归的假设函数，这样 对假设函数的解释 :给定 x ，根据选择的参数计算出y = 1 的概率 ，具体的概率公式如下 :$$h_\theta(x) = P(y=1|x; \theta)$$ Sigmoid - Python:1234import numpy as npdef sigmoid(z): return 1 / (1 + np.exp(-z)) 判定边界(decision boundary)如何得出判定边界 :在 逻辑回归的假设函数中，但凡输出结果 $h_\theta(x)$大于 0.5 的，我们都将预测结果 $y$ 收敛于 1 ；小于 0.5 的，收敛于 0 ；而恰好等于 0.5 的，收敛1 或 0 都可以，我们可以自己设定它如何收敛。由此，我们的输出值就都在 0 到 1 之间了。而当 $h_\theta(x)$ 大于 0.5 时，$\theta^Tx$ 大于 0.5， $h_\theta(x)$ 小于 0.5 时，$\theta^Tx$ 小于 0.5， $h_\theta(x)$ 等于 0.5 时，$\theta^Tx$ 等于 0.5。当然，具体的阈值是可以调整的，比如说你是一个比较保守的人，可能将阈值设为 0.9 ，也就是说有超过 90% 的把握，才相信这个$y$收敛于 1 。 由此，我们能够绘制出判定边界 :$$\theta^Tx = 0$$ 关于判定边界 : 决策边界不是训练集的属性，而是假设本身及其参数的属性 只要给出确定的参数$\theta$，就确定了我们的决策边界 高阶多项式(多个特征变量)能够让我们得到更复杂的决策边界 逻辑回归的代价函数，梯度下降自动拟合$\theta$，以及代价函数的推导过程逻辑回归的代价函数 :$$J(\theta) = \frac{1}{m}\sum_{i=1}^{m}Cost(h_\theta(x^{(i)}),y^{(i)})$$其中$Cost$ :$$Cost(h_\theta(x),y) = -ylog(h_\theta(x)) - (1-y)log(1-h_\theta(x))$$因此$J(\theta)$ :$$J(\theta) =-\frac{1}{m}[\sum_{i=1}^{m} y^{(i)}log(h_\theta(x^{(i)})) + (1-y^{(i)})log(1-h_\theta(x^{(i)}))]$$ 使用对数几率的原因: 代价函数 $J(\theta)$ 会是一个凸函数，并且没有局部最优值。否则我们的代价函数将是一个非凸函数。 逻辑回归的梯度下降算法 :Repeat {$$\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j} J(\theta)$$(simultaneously update all )} 求导后得到： Repeat {$$\theta_j := \theta_j - \alpha\sum_{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ (simultaneously update all )} ps : 逻辑回归梯度下降结果与线性回归梯度下降结果一致，但其中的$h_\theta(x)$并不一样，因此本质上是不同的。 关于特征缩放和均值归一化:思想:在有多个特征的情况下，如果你能确保这些不同的特征都处在一个相近的范围，这样梯度下降法就能更快地收敛。使代价函数$J(θ)$的轮廓图的形状就会变得更圆一些。 做法:一般地，我们执行特征缩放时，我们通常将特征的取值约束到接近−1到+1的范围。其中，特征x0总是等于1，因此这已经是在这个范围内了，但对于其他的特征，我们需要通过除以不同的数来让它们处于同一范围内。除了在特征缩放中将特征除以最大值以外，有时候我们也会进行一个称为均值归一化的操作:$$x_n = \frac{x_n-μ_n}{s_n}$$其中，$μ_n$是平均值，$s_n$是标准差 好处: 更好的进行梯度下降，提高代价函数的收敛速度 提高代价函数求解的精度 更适合解决大型机器学习的问题​ 其他相较于梯度下降算法更好的的令代价函数最小的算法(高级优化[超纲])常用算法: 共轭梯度(Conjugate Gradient) 局部优化法(BFGS - Broyden fletcher goldfarb shann) 有限内存局部优化法(LBFGS) 好处: 这些算法内部有一个智能的内部循环(线性搜索算法)，能够尝试不同的 $\alpha​$ 并自动的选择一个好的学习速率 $\alpha​$ ，这样就不需要手动选择 $\alpha​$ 收敛速度通常比梯度下降算法更快速 缺点: 比梯度下降算法更加复杂 使用逻辑回归算法解决多类别问题思想:将多分类问题拆分成多个二分类问题并得出多个模型。最后，在我们需要做预测时，我们将所有的分类机都运行一遍，然后对每一个输入变量，都选择最高可能性的输出变量。 做法:我们将多个类中的一个类标记为正向类（$y=1$），然后将其他所有类都标记为负向类，这个模型记作$h_\theta^{\left( 1 \right)}\left( x \right)$。接着，类似地我们选择另一个类标记为正向类（$y=2$），再将其它类都标记为负向类，将这个模型记作 $h_\theta^{\left( 2 \right)}\left( x \right)$,依此类推。最后我们得到一系列的模型简记为： $h_\theta^{\left( i \right)}\left( x \right)=p\left( y=i|x;\theta \right)$其中：$i=\left( 1,2,3….k \right)$ 。然后我们将这多个逻辑回归分类器进行训练并得出最终模型：$h_\theta^{\left( i \right)}\left( x \right)$， 其中 $i$ 对应每一个可能的 $y=i$，最后，当我们需要进行预测时，输入一个新的 $x$ 值，我们要做的就是在这多个分类器里面输入 $x$，然后在多个分类器得出的结果中，选出一个最大的$ i$，即$\mathop{\max}\limits_i\,h_\theta^{\left( i \right)}\left( x \right)$。 逻辑回归梯度下降中代价函数求导过程]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习-向量化]]></title>
    <url>%2F2018%2F10%2F25%2FMechineLearning-%E5%90%91%E9%87%8F%E5%8C%96%2F</url>
    <content type="text"><![CDATA[向量化 - 传统累加运算 - 代码实现:1234567891011121314151617181920import timeimport numpy as np# 定义两组向量vector1 = np.random.rand(100000)vector2 = np.random.rand(100000)# 使用向量化start_time = time.time() # 开始时间res = np.dot(vector1, vector2) # 向量直接相乘得到最终结果end_time = time.time() # 结束时间print("Vectorized: " + str((end_time - start_time)*1000) + "ms" + " res =" + str(res))# 使用for循环res = 0start_time = time.time() # 开始时间for i in range(100000): # 传统的累加运算,需要累加100000次 res += vector1[i] * vector2[i]end_time = time.time() # 结束时间print("For loop: " + str((end_time - start_time)*1000) + "ms" + " res =" + str(res)) 结果对比:12Vectorized :1.0001659393310547ms res =24969.775960643143For loop:79.94818687438965ms res =24969.775960642968 ​ 从执行结果来看向量化的运算速度要比非向量化的运算快了近80倍，而这个对比结果还会随着运算集的数目增加而增加。 为什么:​ CPU 与 GPU 都能够使用 SIMD 指令进行并行化操作，即以同步方式，在同一时间内执行同一条指令。一般来讲可扩展的深度学习都在 GPU 上做，但其实 CPU 也不是太差，只是没有 GPU 擅长。 ​ 而 Python 的 numpy 的一些内置函数能够充分利用并行化来加速运算，比如 np.dot，因此，不到逼不得已，还是不要使用 for 循环吧 注:​ GPU - 图形处理器也，叫做图像处理单元，显卡的处理器。与 CPU 类似，只不过 GPU 是专为执行复杂的数学和几何计算而设计的，这些计算是图形渲染所必需的。​ SIMD - 单指令多数据流，以同步方式，在同一时间内执行同一条指令。]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
